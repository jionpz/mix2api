# mix2api 示例配置（请复制为 .env 并按需修改）

# 服务端口
PORT=3001

# 上游基础地址（敏感/私有信息建议只放在 .env，不要写进代码或提交到仓库）
UPSTREAM_API_BASE=https://your-upstream.example
UPSTREAM_CHAT_PATH=/v2/chats

# 可选：上游需要的 Referer / Accept-Language
UPSTREAM_REFERER=
UPSTREAM_ACCEPT_LANGUAGE=zh-CN,zh;q=0.9,en;q=0.8

# 上游网络
UPSTREAM_TIMEOUT_MS=180000
UPSTREAM_RETRY_COUNT=0
UPSTREAM_RETRY_BASE_MS=250
UPSTREAM_KEEP_ALIVE=true

# 鉴权（建议与 new-api 搭配时启用“入站鉴权 + 上游静态 token”）
# 入站：new-api → mix2api
INBOUND_AUTH_MODE=bearer
INBOUND_BEARER_TOKEN=

# 上游：mix2api → 上游模型网站
# - pass_through：使用入站 Bearer 作为上游 token（兼容旧用法）
# - static：使用 UPSTREAM_BEARER_TOKEN
# - managed：由 mix2api 自动获取/续期上游 token
# - none：不带 Authorization
UPSTREAM_AUTH_MODE=pass_through
UPSTREAM_BEARER_TOKEN=
UPSTREAM_TOKEN_URL=
UPSTREAM_TOKEN_PATH=/v2/token
UPSTREAM_TOKEN_METHOD=POST
UPSTREAM_TOKEN_HEADERS_JSON=
UPSTREAM_TOKEN_BODY_JSON=
UPSTREAM_TOKEN_FIELD=access_token
UPSTREAM_TOKEN_EXPIRES_IN_FIELD=expires_in
UPSTREAM_TOKEN_TIMEOUT_MS=10000
UPSTREAM_TOKEN_EXPIRY_SKEW_MS=60000
UPSTREAM_AUTH_RECOVERY_RETRY=1

# 日志
LOG_HEADERS=false
LOG_BODIES=false
LOG_TOOL_PARSE=false
LOG_TOOL_SELECTION=false
LOG_TOKEN_INFO=false
EXPOSE_STACK=false

# 请求体限制
BODY_SIZE_LIMIT=5mb

# 工具调用（OpenAI tools/function calling）
FORCE_TOOL_CALL=0
TOOL_KEEP_ALL=true
TOOL_MAX_COUNT=15
TOOL_DESC_MAX_CHARS=500
SYSTEM_PROMPT_MAX_CHARS=10000
# TOOL_INSTRUCTION_MODE: query / messages / both / none
TOOL_INSTRUCTION_MODE=both
# 默认不向上游透传 tools（避免上游误以为要执行工具）
SEND_UPSTREAM_TOOLS=false

# Persona（可选）：固定指定一个 persona_id（也可由请求头 x-persona-id / 请求体 persona_id 覆盖）
DEFAULT_PERSONA_ID=

# Session 会话管理
SESSION_TTL_MS=1800000
# session store 后端：
# - redis：优先使用 Redis（默认），不可用时会自动降级到内存
# - auto：配置了 REDIS_URL 则用 Redis，否则内存
# - memory：仅内存
SESSION_STORE_MODE=redis
REDIS_URL=
REDIS_CONNECT_TIMEOUT_MS=2000
REDIS_SESSION_PREFIX=mix2api:session
# session store key 的计算方式：
# - model：仅按 model 维度（最简单）
# - auth：按入站 Authorization 的指纹隔离（适合 new-api 作为入口时区分不同渠道/Key）
# - auth_model_client：按 auth 指纹 + model + client 隔离（默认）
SESSION_KEY_MODE=auth_model_client
# 可选：如果调用方能提供稳定 header 来区分会话来源，可设置该 header 名称
SESSION_KEY_HEADER=x-session-key

# 上下文记忆（仅在新会话时生效，有 session_id 时上游自动管理上下文）
INCLUDE_CONTEXT_IN_QUERY=false
CONTEXT_MAX_TURNS=15
CONTEXT_MAX_CHARS=20000
CONTEXT_USER_MAX_CHARS=5000
CONTEXT_ASST_MAX_CHARS=3000
CONTEXT_SMART_COMPRESS=true
CONTEXT_PRESERVE_TOOL_CHAINS=true
QUERY_MAX_CHARS=30000
TOOL_RESULT_MAX_CHARS=20000

# 发送给上游的 messages 裁剪（避免重复占 token）
UPSTREAM_MESSAGES_MAX=20
UPSTREAM_MESSAGE_MAX_CHARS=8000

# 模型列表（/v1/models）
MODEL_LIST=mix/qwen-3-235b-instruct,mix/claude-sonnet-4-5

# 模型能力画像（用于上下文预算规划）
# JSON 对象：key 为模型名（支持完整名或 slug），value 为画像参数
# 字段：
# - context_window: 模型上下文窗口上限
# - max_input_tokens: 单次请求最大输入 token 预算
# - max_new_tokens: 单次请求最大新生成 token 预算
# 行为：
# - 请求输入估算超出 max_input_tokens 时返回 400(context_length_exceeded)
# - 输入估算同时考虑 messages 与 tools 负载
# - 预留输出预算后可用输入预算：available_input_tokens=min(max_input_tokens, context_window-reserved_output_tokens)
# - max_tokens / max_completion_tokens 会被映射并裁剪到 max_new_tokens
# - 未显式传 max_tokens 时，默认预留 TOKEN_BUDGET_DEFAULT_RESERVED_OUTPUT_TOKENS
# 示例：
# MODEL_PROFILE_JSON={"mix/qwen-3-235b-instruct":{"context_window":200000,"max_input_tokens":160000,"max_new_tokens":8192}}
MODEL_PROFILE_JSON=
MODEL_PROFILE_DEFAULT_CONTEXT_WINDOW=200000
MODEL_PROFILE_DEFAULT_MAX_INPUT_TOKENS=160000
MODEL_PROFILE_DEFAULT_MAX_NEW_TOKENS=8192
TOKEN_BUDGET_DEFAULT_RESERVED_OUTPUT_TOKENS=1024
# fallback 告警去重缓存上限（防止未知 model 持续增长导致内存占用增加）
MODEL_PROFILE_FALLBACK_WARN_CACHE_SIZE=1024

# 输入预算超限时的历史裁剪策略（Story 6.3）
# - 首轮预检 reject 后，触发“保 system + 最近关键消息”二次构造
# - 可选将被裁剪历史压缩为摘要记忆块注入 query
BUDGET_TRIM_RECENT_MESSAGES=6
BUDGET_TRIM_MESSAGE_MAX_CHARS=1200
BUDGET_HISTORY_SUMMARY_ENABLED=false
BUDGET_HISTORY_SUMMARY_MAX_CHARS=600
BUDGET_HISTORY_SUMMARY_MAX_LINES=10
