# mix2api 示例配置（请复制为 .env 并按需修改）

# 服务端口
PORT=3001

# 上游基础地址（敏感/私有信息建议只放在 .env，不要写进代码或提交到仓库）
UPSTREAM_API_BASE=https://your-upstream.example
UPSTREAM_CHAT_PATH=/v2/chats

# 可选：上游需要的 Referer / Accept-Language
UPSTREAM_REFERER=
UPSTREAM_ACCEPT_LANGUAGE=zh-CN,zh;q=0.9,en;q=0.8

# 上游网络
UPSTREAM_TIMEOUT_MS=180000
UPSTREAM_RETRY_COUNT=0
UPSTREAM_RETRY_BASE_MS=250
UPSTREAM_KEEP_ALIVE=true

# 鉴权（建议与 new-api 搭配时启用“入站鉴权 + 上游静态 token”）
# 入站：new-api → mix2api
INBOUND_AUTH_MODE=bearer
INBOUND_BEARER_TOKEN=

# 上游：mix2api → 上游模型网站
# - pass_through：使用入站 Bearer 作为上游 token（兼容旧用法）
# - static：使用 UPSTREAM_BEARER_TOKEN
# - managed：由 mix2api 自动获取/续期上游 token
# - none：不带 Authorization
UPSTREAM_AUTH_MODE=pass_through
UPSTREAM_BEARER_TOKEN=
UPSTREAM_TOKEN_URL=
UPSTREAM_TOKEN_PATH=/v2/token
UPSTREAM_TOKEN_METHOD=POST
UPSTREAM_TOKEN_HEADERS_JSON=
UPSTREAM_TOKEN_BODY_JSON=
UPSTREAM_TOKEN_FIELD=access_token
UPSTREAM_TOKEN_EXPIRES_IN_FIELD=expires_in
UPSTREAM_TOKEN_TIMEOUT_MS=10000
UPSTREAM_TOKEN_EXPIRY_SKEW_MS=60000
UPSTREAM_AUTH_RECOVERY_RETRY=1

# 日志
LOG_HEADERS=false
LOG_BODIES=false
LOG_TOOL_PARSE=false
LOG_TOOL_SELECTION=false
LOG_TOKEN_INFO=false
EXPOSE_STACK=false

# 请求体限制
BODY_SIZE_LIMIT=5mb

# 工具调用（OpenAI tools/function calling）
FORCE_TOOL_CALL=0
TOOL_KEEP_ALL=true
TOOL_MAX_COUNT=15
TOOL_DESC_MAX_CHARS=500
SYSTEM_PROMPT_MAX_CHARS=10000
# TOOL_INSTRUCTION_MODE: query / messages / both / none
TOOL_INSTRUCTION_MODE=both
# 默认不向上游透传 tools（避免上游误以为要执行工具）
SEND_UPSTREAM_TOOLS=false

# Persona（可选）：固定指定一个 persona_id（也可由请求头 x-persona-id / 请求体 persona_id 覆盖）
DEFAULT_PERSONA_ID=

# Session 会话管理
SESSION_TTL_MS=1800000
# session store key 的计算方式：
# - model：仅按 model 维度（最简单）
# - auth：按入站 Authorization 的指纹隔离（适合 new-api 作为入口时区分不同渠道/Key）
# - auth_model_client：按 auth 指纹 + model + client 隔离（默认）
SESSION_KEY_MODE=auth_model_client
# 可选：如果调用方能提供稳定 header 来区分会话来源，可设置该 header 名称
SESSION_KEY_HEADER=x-session-key

# 上下文记忆（仅在新会话时生效，有 session_id 时上游自动管理上下文）
INCLUDE_CONTEXT_IN_QUERY=false
CONTEXT_MAX_TURNS=15
CONTEXT_MAX_CHARS=20000
CONTEXT_USER_MAX_CHARS=5000
CONTEXT_ASST_MAX_CHARS=3000
CONTEXT_SMART_COMPRESS=true
CONTEXT_PRESERVE_TOOL_CHAINS=true
QUERY_MAX_CHARS=30000
TOOL_RESULT_MAX_CHARS=20000

# 发送给上游的 messages 裁剪（避免重复占 token）
UPSTREAM_MESSAGES_MAX=20
UPSTREAM_MESSAGE_MAX_CHARS=8000

# 模型列表（/v1/models）
MODEL_LIST=mix/qwen-3-235b-instruct,mix/claude-sonnet-4-5
